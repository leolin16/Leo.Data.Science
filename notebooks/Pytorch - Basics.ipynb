{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !conda install pytorch torchvision -c pytorch -y\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-d\n",
    "tensor_array = torch.Tensor([[1,2],[4,5]])\n",
    "tensor_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_uninitialized = torch.Tensor(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the total number of elements: shape\n",
    "torch.numel(tensor_uninitialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1392, 0.5731, 0.0988],\n",
       "        [0.2479, 0.1450, 0.4872]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the tensor directly via torch.rand(allocate memory for valid values)\n",
    "tensor_initialized = torch.rand(2,3)\n",
    "tensor_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0, -1],\n",
       "        [ 0,  1,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [-1, -1,  0],\n",
       "        [ 0,  1,  0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randn for initializing normal distributed values?\n",
    "tensor_int = torch.randn(5,3).type(torch.IntTensor)\n",
    "tensor_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize long value tensor\n",
    "tensor_long = torch.LongTensor([1.0,2.0,3.0])\n",
    "tensor_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   5,   1, 251], dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# byte: unsigned integer: 0~255\n",
    "tensor_byte = torch.ByteTensor([0,261,1,-5])\n",
    "tensor_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ones = torch.ones(10)\n",
    "tensor_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_zeroes = torch.zeros(10)\n",
    "tensor_zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_eye = torch.eye(3)\n",
    "tensor_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero = torch.nonzero(tensor_eye) # to find the index of all elements in tensor that are non zero\n",
    "non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ones_shape_eye = torch.ones_like(tensor_eye)\n",
    "tensor_ones_shape_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ones_shape_xyz = torch.ones_like(non_zero)\n",
    "tensor_ones_shape_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace(modify existing tensor) tensor operation is with _\n",
    "initial_tensor = torch.rand(3,3)\n",
    "initial_tensor.fill_(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 7.],\n",
       "        [7., 7., 7.],\n",
       "        [7., 7., 7.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of place operation: give a new tensor, origin not modified\n",
    "new_tensor = initial_tensor.add(4)\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 8., 8.],\n",
       "        [8., 8., 8.],\n",
       "        [8., 8., 8.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inplace again\n",
    "initial_tensor.add_(5)\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert with numpy\n",
    "import numpy as np\n",
    "numpy_arr = np.array([1,2,3])\n",
    "numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(numpy_arr)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_from_tensor = tensor.numpy()\n",
    "numpy_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arr[1] = 4\n",
    "numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0094, 0.9486, 0.7098],\n",
       "        [0.4454, 0.2457, 0.5283]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice function\n",
    "initial_tensor = torch.rand(2,3)\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5047)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_element = initial_tensor[0,2]\n",
    "one_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5179, 0.5047],\n",
       "        [0.7637, 0.7021]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_matrix = initial_tensor[:,1:]\n",
    "partial_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch view like numpy reshape\n",
    "resized_tensor = initial_tensor.view(3,2)\n",
    "resized_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_tensor = initial_tensor.view(-1,6)\n",
    "resized_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7986, 0.5179, 0.5047, 0.0437, 0.7637, 0.7021]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0094, 0.9486, 0.7098],\n",
       "        [0.4454, 0.2457, 0.5283]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tensor, sorted_indices = torch.sort(initial_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0094, 0.7098, 0.9486],\n",
       "        [0.2457, 0.4454, 0.5283]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 1],\n",
       "        [1, 0, 2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5325, -0.5147, -0.0353, -1.8224],\n",
       "        [-0.9944, -0.2572,  0.4852, -0.0822],\n",
       "        [ 0.1894,  1.2826,  0.9643,  0.1617]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "sorted, indices = torch.sort(x,dim=0)\n",
    "sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0, 0, 2],\n",
       "        [0, 1, 2, 1],\n",
       "        [1, 2, 1, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 热身：用numpy实现两层神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h = W_1X + b_1$\n",
    "$a = max(0, h)\n",
    "${y_hat} = W_2a + b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26711451.265976667\n",
      "1 21393256.89459321\n",
      "2 18417729.024671633\n",
      "3 15714239.33957896\n",
      "4 12759011.19823733\n",
      "5 9730331.645010393\n",
      "6 7051155.374207037\n",
      "7 4942573.136024397\n",
      "8 3434908.022678569\n",
      "9 2411698.6524730762\n",
      "10 1736187.5452568007\n",
      "11 1290814.5374552938\n",
      "12 993240.4241178567\n",
      "13 788844.9384683988\n",
      "14 643843.2653339806\n",
      "15 537128.3616961685\n",
      "16 455904.4511038303\n",
      "17 392181.96362324106\n",
      "18 340899.17659566866\n",
      "19 298709.2135219119\n",
      "20 263416.2580423041\n",
      "21 233528.07886463858\n",
      "22 207994.05071831855\n",
      "23 185954.15296971885\n",
      "24 166838.19109721488\n",
      "25 150115.69501523697\n",
      "26 135419.22983223337\n",
      "27 122522.43404054674\n",
      "28 111097.21004149289\n",
      "29 100947.95061644295\n",
      "30 91904.65990683803\n",
      "31 83817.6343186279\n",
      "32 76571.407577541\n",
      "33 70070.02830536626\n",
      "34 64218.767054005366\n",
      "35 58940.28617750328\n",
      "36 54167.23492453193\n",
      "37 49847.37943528049\n",
      "38 45927.949975485986\n",
      "39 42372.16797663368\n",
      "40 39136.7283890004\n",
      "41 36186.27731196976\n",
      "42 33491.6960247533\n",
      "43 31027.97340521956\n",
      "44 28772.012302034913\n",
      "45 26703.794768295684\n",
      "46 24805.70249013509\n",
      "47 23061.51605759585\n",
      "48 21457.755117530432\n",
      "49 19980.052599445145\n",
      "50 18617.921685042493\n",
      "51 17361.99379970104\n",
      "52 16203.077951401438\n",
      "53 15133.589072373677\n",
      "54 14143.502169613528\n",
      "55 13227.539549469187\n",
      "56 12378.779967006805\n",
      "57 11590.561135547996\n",
      "58 10859.30835613948\n",
      "59 10181.211961337372\n",
      "60 9550.546609714358\n",
      "61 8963.617656503568\n",
      "62 8416.76759853068\n",
      "63 7907.04373383312\n",
      "64 7432.0550273596255\n",
      "65 6988.697755408057\n",
      "66 6574.674576081907\n",
      "67 6187.781125646248\n",
      "68 5826.271112736105\n",
      "69 5488.021928553855\n",
      "70 5171.329029893809\n",
      "71 4874.9298766092\n",
      "72 4597.044349063279\n",
      "73 4336.844945074229\n",
      "74 4092.7329806639664\n",
      "75 3863.5593945520186\n",
      "76 3648.5022915285476\n",
      "77 3446.5264738091073\n",
      "78 3256.8223765020152\n",
      "79 3078.550044573912\n",
      "80 2910.8360163045745\n",
      "81 2753.11322501288\n",
      "82 2604.7101048450886\n",
      "83 2464.9653658300404\n",
      "84 2333.430883202759\n",
      "85 2209.487437291406\n",
      "86 2092.66469187465\n",
      "87 1982.5186009867748\n",
      "88 1878.6403674249989\n",
      "89 1780.6771718615023\n",
      "90 1688.2214338990404\n",
      "91 1600.9712820452216\n",
      "92 1518.5853757867023\n",
      "93 1440.7971738056285\n",
      "94 1367.338827814754\n",
      "95 1297.921297997857\n",
      "96 1232.2635307991843\n",
      "97 1170.1794400940007\n",
      "98 1111.47911152714\n",
      "99 1055.920256820813\n",
      "100 1003.3397054045481\n",
      "101 953.5733236756233\n",
      "102 906.4595050699875\n",
      "103 861.8300219086586\n",
      "104 819.5738155844816\n",
      "105 779.5218519519997\n",
      "106 741.5728212462618\n",
      "107 705.6090848113745\n",
      "108 671.4895691365623\n",
      "109 639.1292591099984\n",
      "110 608.4360315536424\n",
      "111 579.3072850624169\n",
      "112 551.6542852409832\n",
      "113 525.4113945411441\n",
      "114 500.50196412780605\n",
      "115 476.8356532014969\n",
      "116 454.36041403219207\n",
      "117 433.0077190768727\n",
      "118 412.7193835861119\n",
      "119 393.44345854937905\n",
      "120 375.1182420318407\n",
      "121 357.69700913839665\n",
      "122 341.13603694014876\n",
      "123 325.3832672660869\n",
      "124 310.3970135955401\n",
      "125 296.1390236329228\n",
      "126 282.58008273746356\n",
      "127 269.6672793933268\n",
      "128 257.3791606741743\n",
      "129 245.68563270177953\n",
      "130 234.54685602108506\n",
      "131 223.94149644572605\n",
      "132 213.8423951520852\n",
      "133 204.22116961171855\n",
      "134 195.05220314282644\n",
      "135 186.31931891509137\n",
      "136 177.99904899535437\n",
      "137 170.06579479196103\n",
      "138 162.50273999673684\n",
      "139 155.29432848031593\n",
      "140 148.41881057266454\n",
      "141 141.86542835127122\n",
      "142 135.6135459728635\n",
      "143 129.65025960751353\n",
      "144 123.96203132310069\n",
      "145 118.5341158719056\n",
      "146 113.35716640650054\n",
      "147 108.41378729014946\n",
      "148 103.6972517707925\n",
      "149 99.19487950074728\n",
      "150 94.89585732194722\n",
      "151 90.7936228707715\n",
      "152 86.87668412506827\n",
      "153 83.13821912433663\n",
      "154 79.56747460927267\n",
      "155 76.15574111638098\n",
      "156 72.89711790689779\n",
      "157 69.78277690688452\n",
      "158 66.80746523226696\n",
      "159 63.96468147771117\n",
      "160 61.24811000808653\n",
      "161 58.651183710749265\n",
      "162 56.169024713671746\n",
      "163 53.79699932728002\n",
      "164 51.52849489135918\n",
      "165 49.358941564405974\n",
      "166 47.28486918956343\n",
      "167 45.30127622054446\n",
      "168 43.40354962473073\n",
      "169 41.58875951575894\n",
      "170 39.85261452132809\n",
      "171 38.19224809898064\n",
      "172 36.603313526640804\n",
      "173 35.08249466404079\n",
      "174 33.627870127409714\n",
      "175 32.235125903509854\n",
      "176 30.902361430917757\n",
      "177 29.627113816823602\n",
      "178 28.405980906531546\n",
      "179 27.23720293727757\n",
      "180 26.118220249970026\n",
      "181 25.04645431272415\n",
      "182 24.02055399977514\n",
      "183 23.037872863053884\n",
      "184 22.096802344355204\n",
      "185 21.195506137358993\n",
      "186 20.332122780130728\n",
      "187 19.50536187649167\n",
      "188 18.713356906044346\n",
      "189 17.954289209396165\n",
      "190 17.22725562631465\n",
      "191 16.530291629026088\n",
      "192 15.862493725694964\n",
      "193 15.22260306594297\n",
      "194 14.609332164086462\n",
      "195 14.021579177847123\n",
      "196 13.45708806515351\n",
      "197 12.915861906145919\n",
      "198 12.397368159580063\n",
      "199 11.900132354316764\n",
      "200 11.423484216629477\n",
      "201 10.966565978134701\n",
      "202 10.528395923662453\n",
      "203 10.108418878988935\n",
      "204 9.705606042653642\n",
      "205 9.319166150700758\n",
      "206 8.948778251071085\n",
      "207 8.593472595909688\n",
      "208 8.252575320799501\n",
      "209 7.92567424679897\n",
      "210 7.612002172313574\n",
      "211 7.311195124175945\n",
      "212 7.022626634004521\n",
      "213 6.745662406287087\n",
      "214 6.47998173382586\n",
      "215 6.224989433466133\n",
      "216 5.980289703867134\n",
      "217 5.745493290825565\n",
      "218 5.520131531199331\n",
      "219 5.303935486512937\n",
      "220 5.096409334869191\n",
      "221 4.897135879258287\n",
      "222 4.705916549546295\n",
      "223 4.522291374537486\n",
      "224 4.346045885197377\n",
      "225 4.176888342867926\n",
      "226 4.014416582952969\n",
      "227 3.8584510978134814\n",
      "228 3.7087169776793334\n",
      "229 3.5648924336719974\n",
      "230 3.4268109101893796\n",
      "231 3.294206820841206\n",
      "232 3.1668256676692317\n",
      "233 3.0445362325062897\n",
      "234 2.9270580845989507\n",
      "235 2.8142039408670163\n",
      "236 2.705842214084667\n",
      "237 2.601721160622736\n",
      "238 2.501692453216625\n",
      "239 2.4056107238476785\n",
      "240 2.3132867960533483\n",
      "241 2.224615981477329\n",
      "242 2.13940925965667\n",
      "243 2.0575423279686573\n",
      "244 1.9788840574775481\n",
      "245 1.9032779906012713\n",
      "246 1.8306218774971406\n",
      "247 1.760815031382924\n",
      "248 1.693732336360613\n",
      "249 1.6292508691660261\n",
      "250 1.5672768832880979\n",
      "251 1.507710297633026\n",
      "252 1.4504606317380062\n",
      "253 1.3954269414330136\n",
      "254 1.3425214990543304\n",
      "255 1.2916808322798452\n",
      "256 1.242788207001173\n",
      "257 1.19577413826427\n",
      "258 1.1505989905488614\n",
      "259 1.1071514835852638\n",
      "260 1.0653756924862947\n",
      "261 1.0252191519031277\n",
      "262 0.986592636015083\n",
      "263 0.9494544258222903\n",
      "264 0.9137436598102142\n",
      "265 0.8793922115925932\n",
      "266 0.8463715713328452\n",
      "267 0.8146089355268215\n",
      "268 0.7840586287209381\n",
      "269 0.7546807649066487\n",
      "270 0.7264137200375091\n",
      "271 0.699226345744987\n",
      "272 0.6730847126195736\n",
      "273 0.6479301617788963\n",
      "274 0.6237424044331813\n",
      "275 0.6004688804259448\n",
      "276 0.578076732518938\n",
      "277 0.5565335189879381\n",
      "278 0.5358080379313488\n",
      "279 0.5158672759905935\n",
      "280 0.4966902857711084\n",
      "281 0.47823445936990533\n",
      "282 0.46047251050502624\n",
      "283 0.44338337507368264\n",
      "284 0.42693567719619785\n",
      "285 0.41110943859243354\n",
      "286 0.39588944247298086\n",
      "287 0.3812303784571552\n",
      "288 0.3671259458647399\n",
      "289 0.35355571989625034\n",
      "290 0.3404912397660863\n",
      "291 0.32791996046835736\n",
      "292 0.31582067008367654\n",
      "293 0.30417199270319784\n",
      "294 0.2929602305408822\n",
      "295 0.28216863038535955\n",
      "296 0.27178364511523834\n",
      "297 0.2617852122261637\n",
      "298 0.2521581686662177\n",
      "299 0.24289062210060824\n",
      "300 0.23397261711951545\n",
      "301 0.2253831435361574\n",
      "302 0.2171134099453237\n",
      "303 0.2091542845522183\n",
      "304 0.20149044486062853\n",
      "305 0.19411182364789914\n",
      "306 0.187007673329297\n",
      "307 0.1801644535626044\n",
      "308 0.17357640472816604\n",
      "309 0.16723493754113727\n",
      "310 0.16112634208581025\n",
      "311 0.1552446049099751\n",
      "312 0.14958193787390162\n",
      "313 0.14412584861043964\n",
      "314 0.1388742466147211\n",
      "315 0.13381518930623243\n",
      "316 0.12894246934421114\n",
      "317 0.12425029867049991\n",
      "318 0.11973038224637525\n",
      "319 0.1153790909793781\n",
      "320 0.11118719961113305\n",
      "321 0.107147829312583\n",
      "322 0.10325806375123864\n",
      "323 0.09951260991458874\n",
      "324 0.09590312788517537\n",
      "325 0.09242674985679852\n",
      "326 0.08907876256561181\n",
      "327 0.08585253322350994\n",
      "328 0.08274551964477687\n",
      "329 0.07975198990189702\n",
      "330 0.07686730197356337\n",
      "331 0.07408880922133175\n",
      "332 0.07141297789591759\n",
      "333 0.06883357321598649\n",
      "334 0.06634903992297943\n",
      "335 0.06395485691883006\n",
      "336 0.06164866602472681\n",
      "337 0.0594263043968074\n",
      "338 0.05728438011050002\n",
      "339 0.05522084461819838\n",
      "340 0.05323361727775126\n",
      "341 0.05131780925072773\n",
      "342 0.04947160743456107\n",
      "343 0.04769248721197775\n",
      "344 0.04597823402700041\n",
      "345 0.044326793399052024\n",
      "346 0.042734798526707016\n",
      "347 0.04120032774517457\n",
      "348 0.03972226888644641\n",
      "349 0.03829752378721396\n",
      "350 0.036923960418816806\n",
      "351 0.03560060806330577\n",
      "352 0.034325058386552594\n",
      "353 0.03309574442536176\n",
      "354 0.0319110745442473\n",
      "355 0.030768970854719496\n",
      "356 0.02966817127178667\n",
      "357 0.02860749785630815\n",
      "358 0.027584699728574608\n",
      "359 0.026598787937738223\n",
      "360 0.025648837670515165\n",
      "361 0.024733149558612937\n",
      "362 0.023850189302113807\n",
      "363 0.022999062997036572\n",
      "364 0.022178737466454983\n",
      "365 0.021388039475404692\n",
      "366 0.020625480069084847\n",
      "367 0.019890419145392538\n",
      "368 0.019182074319070985\n",
      "369 0.01849915064371909\n",
      "370 0.017840504327053152\n",
      "371 0.017205630880284022\n",
      "372 0.016593537488909745\n",
      "373 0.016003508897660654\n",
      "374 0.015434647664950521\n",
      "375 0.01488603597153007\n",
      "376 0.014357215545171081\n",
      "377 0.013847458359238335\n",
      "378 0.013355682779999782\n",
      "379 0.012881531792404297\n",
      "380 0.012424582416721917\n",
      "381 0.011983875196841881\n",
      "382 0.01155892571135685\n",
      "383 0.011149127316691529\n",
      "384 0.010754034002628808\n",
      "385 0.010373014684616749\n",
      "386 0.010005594671456456\n",
      "387 0.009651238015676276\n",
      "388 0.009309749133079713\n",
      "389 0.008980306613814245\n",
      "390 0.008662572687302977\n",
      "391 0.008356192384884421\n",
      "392 0.00806077548105295\n",
      "393 0.007775800161733994\n",
      "394 0.007501005365376945\n",
      "395 0.007235994601953676\n",
      "396 0.006980546644817081\n",
      "397 0.006734022798078861\n",
      "398 0.006496262844327387\n",
      "399 0.006267077261678845\n",
      "400 0.006045955824261997\n",
      "401 0.005832629966875933\n",
      "402 0.0056269960957381\n",
      "403 0.005428678900961466\n",
      "404 0.005237317759066666\n",
      "405 0.005052780447694221\n",
      "406 0.00487478425828045\n",
      "407 0.004703096855161933\n",
      "408 0.004537506589374457\n",
      "409 0.004377766886345134\n",
      "410 0.004223727045867008\n",
      "411 0.004075132846488739\n",
      "412 0.003931763232461976\n",
      "413 0.0037934884341397322\n",
      "414 0.00366012525352424\n",
      "415 0.003531471374629514\n",
      "416 0.0034073615606492985\n",
      "417 0.0032876535680115065\n",
      "418 0.0031721682397278647\n",
      "419 0.0030607662688651384\n",
      "420 0.0029532817756589866\n",
      "421 0.002849631944817257\n",
      "422 0.002749635032507713\n",
      "423 0.0026531299265176236\n",
      "424 0.002560066077661076\n",
      "425 0.0024702871162981172\n",
      "426 0.0023836448563549512\n",
      "427 0.00230007675784336\n",
      "428 0.002219495821638314\n",
      "429 0.0021416941419739803\n",
      "430 0.002066648137820545\n",
      "431 0.001994273286538081\n",
      "432 0.0019244207702710167\n",
      "433 0.00185702901736641\n",
      "434 0.001792030015420416\n",
      "435 0.0017293117918999123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436 0.0016687917440608986\n",
      "437 0.0016103937948510165\n",
      "438 0.0015540644207315505\n",
      "439 0.0014997170386311539\n",
      "440 0.0014472708155018207\n",
      "441 0.0013966739220545032\n",
      "442 0.0013478610111159724\n",
      "443 0.0013007502872133718\n",
      "444 0.0012552944462782994\n",
      "445 0.0012114491315727482\n",
      "446 0.0011691289928890288\n",
      "447 0.0011283025552919752\n",
      "448 0.0010889046240254339\n",
      "449 0.0010508841403587346\n",
      "450 0.0010142094245556956\n",
      "451 0.0009788101125698676\n",
      "452 0.0009446592022519673\n",
      "453 0.0009117069865898169\n",
      "454 0.0008798981240069844\n",
      "455 0.0008492154966952158\n",
      "456 0.000819604546231861\n",
      "457 0.0007910240488567588\n",
      "458 0.0007634567382728881\n",
      "459 0.0007368503114828951\n",
      "460 0.0007111673909488548\n",
      "461 0.0006863895428321836\n",
      "462 0.0006624817797112176\n",
      "463 0.0006394046590291453\n",
      "464 0.0006171348028907205\n",
      "465 0.0005956520385995858\n",
      "466 0.0005749128320285316\n",
      "467 0.0005548971436981323\n",
      "468 0.0005355844934506449\n",
      "469 0.0005169500508109225\n",
      "470 0.0004989611343414821\n",
      "471 0.0004816007151845353\n",
      "472 0.0004648517710732606\n",
      "473 0.00044868262244254233\n",
      "474 0.00043307636237820244\n",
      "475 0.0004180246353973841\n",
      "476 0.0004034897006814298\n",
      "477 0.00038946166469962956\n",
      "478 0.0003759303217576905\n",
      "479 0.0003628635053914243\n",
      "480 0.00035025304313332435\n",
      "481 0.0003380892133464555\n",
      "482 0.0003263454818705796\n",
      "483 0.0003150082984789853\n",
      "484 0.00030406949463086396\n",
      "485 0.0002935117835490351\n",
      "486 0.0002833198446162427\n",
      "487 0.0002734839048784991\n",
      "488 0.00026399387296370525\n",
      "489 0.0002548305559238812\n",
      "490 0.00024598553899057277\n",
      "491 0.00023745263819446524\n",
      "492 0.0002292144076685411\n",
      "493 0.0002212616588050667\n",
      "494 0.00021358995290128195\n",
      "495 0.0002061809073510665\n",
      "496 0.00019902941477962214\n",
      "497 0.00019213071785146264\n",
      "498 0.000185468948978466\n",
      "499 0.00017903898850494144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建训练数据\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    h = x.dot(w1) # N * H\n",
    "    h_relu = np.maximum(h, 0) # N * H\n",
    "    y_pred = h_relu.dot(w2) # N * D_out\n",
    "    \n",
    "    # compute loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(it, loss)\n",
    "    \n",
    "    # Backward pass\n",
    "    # compute the gradiant\n",
    "    #     y = ax + b\n",
    "    #     dy / dx = a\n",
    "    #     dy / da = x\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    # update weights of w1 and w2\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "w1 = torch.randn(D_in, H)\n",
    "w2 = torch.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    h = x.mm(w1) # N * H\n",
    "    h_relu = h.clamp(min=0) # N * H\n",
    "    y_pred = h_relu.mm(w2) # N * D_out\n",
    "    \n",
    "    # compute loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(it, loss)\n",
    "    \n",
    "    # Backward pass\n",
    "    # compute the gradiant\n",
    "    #     y = ax + b\n",
    "    #     dy / dx = a\n",
    "    #     dy / da = x\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.T)\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    # update weights of w1 and w2\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "y = w*x + b # y = 2*1 + 3\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# dy / dw = x\n",
    "print(w.grad)\n",
    "print(x.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
